#!/usr/bin/env python3
"""
æ™ºèƒ½å†°ç®±ç³»ç»Ÿæ¨èæ•°æ®é›†ä¸‹è½½è„šæœ¬
æ”¯æŒè‡ªåŠ¨ä¸‹è½½å’Œé¢„å¤„ç†å¤šä¸ªå…¬å¼€æ•°æ®é›†
"""

import os
import sys
import logging
import argparse
import requests
import tarfile
import zipfile
from pathlib import Path
import json
from urllib.parse import urlparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class DatasetDownloader:
    """æ•°æ®é›†ä¸‹è½½å™¨"""
    
    def __init__(self, download_dir="datasets"):
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(__name__)
        
        # æ¨èæ•°æ®é›†é…ç½®
        self.datasets = {
            'food101': {
                'name': 'Food-101',
                'url': 'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',
                'file_size': '5.2GB',
                'description': '101ç§é£Ÿç‰©ç±»åˆ«ï¼Œæ¯ç±»1000å¼ å›¾åƒ',
                'categories': 101,
                'images': 101000,
                'license': 'Academic Use',
                'suitable_for': ['é£Ÿç‰©åˆ†ç±»', 'ç‰¹å¾å­¦ä¹ ', 'è¿ç§»å­¦ä¹ ']
            },
            'open_images_food': {
                'name': 'Open Images Dataset (Food Subset)',
                'url': 'custom_download',  # éœ€è¦è‡ªå®šä¹‰ä¸‹è½½é€»è¾‘
                'file_size': '~2GB',
                'description': 'Googleå¼€æ”¾å›¾åƒæ•°æ®é›†çš„é£Ÿç‰©å­é›†',
                'categories': 50,
                'images': 20000,
                'license': 'CC BY 2.0',
                'suitable_for': ['ç‰©ä½“æ£€æµ‹', 'å¤šæ ‡ç­¾åˆ†ç±»']
            },
            'usda_food': {
                'name': 'USDA Food Images',
                'url': 'manual_download',  # éœ€è¦æ‰‹åŠ¨ç”³è¯·
                'file_size': '~3GB',
                'description': 'ç¾å›½å†œä¸šéƒ¨é£Ÿç‰©å›¾åƒæ•°æ®é›†',
                'categories': 'Various',
                'images': 50000,
                'license': 'Public Domain',
                'suitable_for': ['è¥å…»åˆ†æ', 'é£Ÿæè¯†åˆ«']
            }
        }
    
    def list_datasets(self):
        """åˆ—å‡ºæ‰€æœ‰æ¨èæ•°æ®é›†"""
        print("ğŸ æ™ºèƒ½å†°ç®±ç³»ç»Ÿæ¨èæ•°æ®é›†")
        print("=" * 60)
        
        for key, dataset in self.datasets.items():
            print(f"\nğŸ“Š {dataset['name']}")
            print(f"   å¤§å°: {dataset['file_size']}")
            print(f"   ç±»åˆ«æ•°: {dataset['categories']}")
            print(f"   å›¾åƒæ•°: {dataset['images']}")
            print(f"   è®¸å¯è¯: {dataset['license']}")
            print(f"   é€‚ç”¨äº: {', '.join(dataset['suitable_for'])}")
            print(f"   æè¿°: {dataset['description']}")
            
            if dataset['url'] == 'manual_download':
                print(f"   âš ï¸  éœ€è¦æ‰‹åŠ¨ä¸‹è½½")
            elif dataset['url'] == 'custom_download':
                print(f"   ğŸ”§ éœ€è¦è‡ªå®šä¹‰ä¸‹è½½è„šæœ¬")
            else:
                print(f"   ğŸ”— å¯è‡ªåŠ¨ä¸‹è½½")
    
    def download_food101(self):
        """ä¸‹è½½Food-101æ•°æ®é›†"""
        dataset_info = self.datasets['food101']
        url = dataset_info['url']
        filename = 'food-101.tar.gz'
        filepath = self.download_dir / filename
        
        self.logger.info(f"å¼€å§‹ä¸‹è½½ {dataset_info['name']}...")
        self.logger.info(f"æ–‡ä»¶å¤§å°: {dataset_info['file_size']}")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if filepath.exists():
                self.logger.info("æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return str(filepath)
            
            # ä¸‹è½½æ–‡ä»¶
            self.logger.info(f"æ­£åœ¨ä» {url} ä¸‹è½½...")
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            print(f"\rä¸‹è½½è¿›åº¦: {progress:.1f}%", end='', flush=True)
            
            print()  # æ¢è¡Œ
            self.logger.info(f"ä¸‹è½½å®Œæˆ: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def extract_food101(self, archive_path):
        """è§£å‹Food-101æ•°æ®é›†"""
        try:
            extract_dir = self.download_dir / "food-101"
            
            if extract_dir.exists():
                self.logger.info("æ•°æ®é›†å·²è§£å‹ï¼Œè·³è¿‡")
                return str(extract_dir)
            
            self.logger.info("æ­£åœ¨è§£å‹æ•°æ®é›†...")
            
            with tarfile.open(archive_path, 'r:gz') as tar:
                tar.extractall(self.download_dir)
            
            self.logger.info(f"è§£å‹å®Œæˆ: {extract_dir}")
            return str(extract_dir)
            
        except Exception as e:
            self.logger.error(f"è§£å‹å¤±è´¥: {e}")
            return None
    
    def filter_food101_for_fridge(self, dataset_path):
        """ç­›é€‰Food-101ä¸­é€‚åˆå†°ç®±çš„é£Ÿç‰©ç±»åˆ«"""
        try:
            dataset_path = Path(dataset_path)
            
            # å®šä¹‰å†°ç®±ç›¸å…³çš„é£Ÿç‰©ç±»åˆ«æ˜ å°„
            fridge_categories = {
                # Food-101ç±»åˆ« -> æ™ºèƒ½å†°ç®±ç±»åˆ«
                'apple_pie': 'fruits',
                'beef_carpaccio': 'beef',
                'beef_tartare': 'beef',
                'cheese_plate': 'cheese',
                'chicken_curry': 'chicken',
                'chicken_wings': 'chicken',
                'eggs_benedict': 'eggs',
                'fish_and_chips': 'fish',
                'fried_chicken': 'chicken',
                'grilled_cheese_sandwich': 'cheese',
                'ice_cream': 'dairy',
                'oysters': 'fish',
                'salmon': 'fish',
                'strawberry_shortcake': 'fruits',
                'sushi': 'fish',
                'tuna_tartare': 'fish'
            }
            
            # åˆ›å»ºç­›é€‰åçš„æ•°æ®é›†ç›®å½•
            filtered_dir = self.download_dir / "food101_fridge_filtered"
            
            # å¤åˆ¶ç›¸å…³ç±»åˆ«çš„å›¾åƒ
            for food101_cat, fridge_cat in fridge_categories.items():
                source_dir = dataset_path / "images" / food101_cat
                
                if not source_dir.exists():
                    self.logger.warning(f"ç±»åˆ«ç›®å½•ä¸å­˜åœ¨: {source_dir}")
                    continue
                
                target_dir = filtered_dir / fridge_cat
                target_dir.mkdir(parents=True, exist_ok=True)
                
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                images = list(source_dir.glob("*.jpg"))
                for i, img in enumerate(images[:100]):  # æ¯ç±»æœ€å¤š100å¼ 
                    target_path = target_dir / f"{food101_cat}_{i:03d}.jpg"
                    if not target_path.exists():
                        import shutil
                        shutil.copy2(img, target_path)
                
                self.logger.info(f"å·²å¤„ç†ç±»åˆ« {food101_cat} -> {fridge_cat}: {len(images)} å¼ å›¾åƒ")
            
            self.logger.info(f"ç­›é€‰å®Œæˆ: {filtered_dir}")
            return str(filtered_dir)
            
        except Exception as e:
            self.logger.error(f"ç­›é€‰å¤±è´¥: {e}")
            return None
    
    def generate_sample_dataset(self, output_dir="ai_model/sample_dataset"):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰"""
        try:
            from src.ai.training.prepare_training_data import create_directory_structure, create_sample_images
            
            # æ™ºèƒ½å†°ç®±æ ¸å¿ƒç±»åˆ«
            categories = ['milk', 'beef', 'vegetables', 'fruits', 'eggs', 
                         'cheese', 'yogurt', 'chicken', 'fish']
            
            self.logger.info("ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†...")
            
            # åˆ›å»ºç›®å½•ç»“æ„
            success = create_directory_structure(output_dir, categories)
            if not success:
                return False
            
            # åˆ›å»ºç¤ºä¾‹å›¾åƒ
            success = create_sample_images(output_dir, categories, images_per_category=20)
            if not success:
                return False
            
            self.logger.info(f"ç¤ºä¾‹æ•°æ®é›†ç”Ÿæˆå®Œæˆ: {output_dir}")
            return output_dir
            
        except Exception as e:
            self.logger.error(f"ç¤ºä¾‹æ•°æ®é›†ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def create_download_guide(self):
        """åˆ›å»ºæ•°æ®é›†ä¸‹è½½æŒ‡å—"""
        guide_content = """# æ™ºèƒ½å†°ç®±ç³»ç»Ÿæ•°æ®é›†ä¸‹è½½æŒ‡å—

## ğŸ æ¨èæ•°æ®é›†

### 1. Food-101 æ•°æ®é›†ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
```bash
# ä¸‹è½½å¹¶é¢„å¤„ç†Food-101æ•°æ®é›†
python scripts/download_datasets.py --dataset food101 --auto-process
```

### 2. Open Images Datasetï¼ˆæ‰‹åŠ¨ä¸‹è½½ï¼‰
1. è®¿é—®: https://opensource.google/projects/open-images-dataset
2. ä¸‹è½½é£Ÿç‰©ç›¸å…³ç±»åˆ«
3. ä½¿ç”¨å¯¼å…¥å·¥å…·å¤„ç†

### 3. è‡ªå®šä¹‰æ•°æ®æ”¶é›†å»ºè®®

#### æ¨èæ”¶é›†ç±»åˆ«ï¼š
- **å¥¶åˆ¶å“**: ç‰›å¥¶ã€é…¸å¥¶ã€å¥¶é…ª
- **è‚‰ç±»**: ç‰›è‚‰ã€é¸¡è‚‰ã€é±¼ç±»
- **å†œäº§å“**: è”¬èœã€æ°´æœ
- **è›‹ç±»**: é¸¡è›‹

#### å›¾åƒè¦æ±‚ï¼š
- åˆ†è¾¨ç‡: è‡³å°‘224x224åƒç´ 
- æ ¼å¼: JPG/PNG
- æ¯ç±»åˆ«: æœ€å°‘50å¼ ï¼Œæ¨è100+å¼ 
- å¤šè§’åº¦æ‹æ‘„ï¼ŒåŒ…å«ä¸åŒå…‰ç…§æ¡ä»¶

## ğŸ“Š æ•°æ®è´¨é‡æ ‡å‡†

### å›¾åƒè´¨é‡è¦æ±‚ï¼š
- âœ… æ¸…æ™°åº¦é«˜ï¼Œæ— æ¨¡ç³Š
- âœ… ä¸»ä½“çªå‡ºï¼ŒèƒŒæ™¯ç®€æ´
- âœ… å…‰ç…§å‡åŒ€ï¼Œè‰²å½©çœŸå®
- âœ… åŒ…å«å¤šç§çŠ¶æ€ï¼ˆæ–°é²œã€åŠæ–°é²œç­‰ï¼‰

### æ ‡æ³¨è¦æ±‚ï¼š
- âœ… ç±»åˆ«æ ‡æ³¨å‡†ç¡®
- âœ… æ–°é²œåº¦è¯„çº§ï¼ˆ1-5åˆ†ï¼‰
- âœ… æ‹æ‘„æ—¶é—´æˆ³
- âœ… å­˜å‚¨ç¯å¢ƒä¿¡æ¯

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python scripts/download_datasets.py --generate-sample

# 2. ä¸‹è½½Food-101æ•°æ®é›†
python scripts/download_datasets.py --dataset food101

# 3. å¯¼å…¥åˆ°è®­ç»ƒç³»ç»Ÿ
python scripts/import_dataset.py --data_type images --source datasets/food101_filtered
```
"""
        
        guide_path = self.download_dir / "DOWNLOAD_GUIDE.md"
        with open(guide_path, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        self.logger.info(f"ä¸‹è½½æŒ‡å—å·²åˆ›å»º: {guide_path}")

def setup_logging(log_level=logging.INFO):
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('dataset_download.log'),
            logging.StreamHandler()
        ]
    )

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½å†°ç®±ç³»ç»Ÿæ•°æ®é›†ä¸‹è½½å·¥å…·")
    
    parser.add_argument("--list", action="store_true",
                       help="åˆ—å‡ºæ‰€æœ‰æ¨èæ•°æ®é›†")
    parser.add_argument("--dataset", type=str,
                       choices=["food101", "open_images", "usda"],
                       help="ä¸‹è½½æŒ‡å®šæ•°æ®é›†")
    parser.add_argument("--generate-sample", action="store_true",
                       help="ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†")
    parser.add_argument("--auto-process", action="store_true",
                       help="è‡ªåŠ¨å¤„ç†ä¸‹è½½çš„æ•°æ®é›†")
    parser.add_argument("--download-dir", type=str, default="datasets",
                       help="ä¸‹è½½ç›®å½•")
    parser.add_argument("--log-level", type=str, default="INFO",
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(getattr(logging, args.log_level))
    logger = logging.getLogger(__name__)
    
    try:
        downloader = DatasetDownloader(args.download_dir)
        
        if args.list:
            # åˆ—å‡ºæ¨èæ•°æ®é›†
            downloader.list_datasets()
            downloader.create_download_guide()
            
        elif args.generate_sample:
            # ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†
            result = downloader.generate_sample_dataset()
            if result:
                logger.info("ç¤ºä¾‹æ•°æ®é›†ç”ŸæˆæˆåŠŸï¼")
                logger.info("ç°åœ¨å¯ä»¥è¿è¡Œ: python scripts/import_dataset.py --data_type images --source ai_model/sample_dataset")
            else:
                logger.error("ç¤ºä¾‹æ•°æ®é›†ç”Ÿæˆå¤±è´¥ï¼")
                
        elif args.dataset == "food101":
            # ä¸‹è½½Food-101æ•°æ®é›†
            archive_path = downloader.download_food101()
            if archive_path:
                extract_path = downloader.extract_food101(archive_path)
                if extract_path and args.auto_process:
                    filtered_path = downloader.filter_food101_for_fridge(extract_path)
                    if filtered_path:
                        logger.info(f"æ•°æ®é›†å·²å‡†å¤‡å°±ç»ª: {filtered_path}")
                        logger.info("ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¼å…¥åˆ°è®­ç»ƒç³»ç»Ÿ:")
                        logger.info(f"python scripts/import_dataset.py --data_type images --source {filtered_path}")
                        
        else:
            logger.info("è¯·æŒ‡å®šæ“ä½œï¼š--list, --dataset, æˆ– --generate-sample")
            
    except Exception as e:
        logger.error(f"æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()