#!/usr/bin/env python3
"""
æ•°æ®é›†è´¨é‡è¯„ä¼°è„šæœ¬
ç”¨äºè¯„ä¼°å¯¼å…¥æ•°æ®é›†çš„è´¨é‡å’Œé€‚ç”¨æ€§
"""

import os
import sys
import logging
import argparse
import json
from pathlib import Path
import cv2
import numpy as np
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class DatasetEvaluator:
    """æ•°æ®é›†è¯„ä¼°å™¨"""
    
    def __init__(self, dataset_path):
        self.dataset_path = Path(dataset_path)
        self.logger = logging.getLogger(__name__)
        
        # æ™ºèƒ½å†°ç®±æ ¸å¿ƒç±»åˆ«
        self.target_categories = [
            'milk', 'beef', 'vegetables', 'fruits', 'eggs',
            'cheese', 'yogurt', 'chicken', 'fish'
        ]
        
        # å›¾åƒè´¨é‡æ ‡å‡†
        self.quality_standards = {
            'min_resolution': (224, 224),
            'max_blur_threshold': 100.0,  # Laplacianæ–¹å·®é˜ˆå€¼
            'min_brightness': 50,
            'max_brightness': 200,
            'min_images_per_category': 50
        }
    
    def evaluate_dataset(self):
        """å…¨é¢è¯„ä¼°æ•°æ®é›†"""
        print("ğŸ” å¼€å§‹æ•°æ®é›†è´¨é‡è¯„ä¼°...")
        
        # åŸºç¡€ç»Ÿè®¡
        stats = self.get_basic_statistics()
        
        # å›¾åƒè´¨é‡åˆ†æ
        quality_report = self.analyze_image_quality()
        
        # ç±»åˆ«åˆ†å¸ƒåˆ†æ
        distribution_report = self.analyze_category_distribution()
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        report = self.generate_evaluation_report(stats, quality_report, distribution_report)
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_report(report)
        
        return report
    
    def get_basic_statistics(self):
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_images': 0,
            'categories': {},
            'datasets': {'train': 0, 'val': 0, 'test': 0},
            'file_formats': Counter(),
            'avg_file_size': 0
        }
        
        total_size = 0
        
        for dataset in ['train', 'val', 'test']:
            dataset_path = self.dataset_path / dataset
            if not dataset_path.exists():
                continue
            
            dataset_images = 0
            for category_dir in dataset_path.iterdir():
                if not category_dir.is_dir():
                    continue
                
                category_name = category_dir.name
                images = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png")) + list(category_dir.glob("*.jpeg"))
                
                category_count = len(images)
                dataset_images += category_count
                
                if category_name not in stats['categories']:
                    stats['categories'][category_name] = {'train': 0, 'val': 0, 'test': 0}
                
                stats['categories'][category_name][dataset] = category_count
                
                # ç»Ÿè®¡æ–‡ä»¶æ ¼å¼å’Œå¤§å°
                for img_path in images:
                    stats['file_formats'][img_path.suffix.lower()] += 1
                    total_size += img_path.stat().st_size
            
            stats['datasets'][dataset] = dataset_images
        
        stats['total_images'] = sum(stats['datasets'].values())
        if stats['total_images'] > 0:
            stats['avg_file_size'] = total_size / stats['total_images'] / (1024 * 1024)  # MB
        
        return stats
    
    def analyze_image_quality(self):
        """åˆ†æå›¾åƒè´¨é‡"""
        quality_report = {
            'resolution_issues': [],
            'blur_issues': [],
            'brightness_issues': [],
            'total_checked': 0,
            'quality_score': 0
        }
        
        sample_size = 100  # æ¯ä¸ªç±»åˆ«æ£€æŸ¥çš„æ ·æœ¬æ•°
        
        for dataset in ['train', 'val', 'test']:
            dataset_path = self.dataset_path / dataset
            if not dataset_path.exists():
                continue
            
            for category_dir in dataset_path.iterdir():
                if not category_dir.is_dir():
                    continue
                
                images = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png"))
                sample_images = images[:min(sample_size, len(images))]
                
                for img_path in sample_images:
                    try:
                        img = cv2.imread(str(img_path))
                        if img is None:
                            continue
                        
                        quality_report['total_checked'] += 1
                        
                        # æ£€æŸ¥åˆ†è¾¨ç‡
                        h, w = img.shape[:2]
                        if h < self.quality_standards['min_resolution'][0] or w < self.quality_standards['min_resolution'][1]:
                            quality_report['resolution_issues'].append({
                                'file': str(img_path),
                                'resolution': (w, h)
                            })
                        
                        # æ£€æŸ¥æ¨¡ç³Šåº¦
                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
                        if blur_score < self.quality_standards['max_blur_threshold']:
                            quality_report['blur_issues'].append({
                                'file': str(img_path),
                                'blur_score': blur_score
                            })
                        
                        # æ£€æŸ¥äº®åº¦
                        brightness = np.mean(gray)
                        if brightness < self.quality_standards['min_brightness'] or brightness > self.quality_standards['max_brightness']:
                            quality_report['brightness_issues'].append({
                                'file': str(img_path),
                                'brightness': brightness
                            })
                        
                    except Exception as e:
                        self.logger.warning(f"æ— æ³•åˆ†æå›¾åƒ {img_path}: {e}")
        
        # è®¡ç®—è´¨é‡è¯„åˆ†
        total_issues = len(quality_report['resolution_issues']) + len(quality_report['blur_issues']) + len(quality_report['brightness_issues'])
        if quality_report['total_checked'] > 0:
            quality_report['quality_score'] = max(0, (quality_report['total_checked'] - total_issues) / quality_report['total_checked'] * 100)
        
        return quality_report
    
    def analyze_category_distribution(self):
        """åˆ†æç±»åˆ«åˆ†å¸ƒ"""
        distribution_report = {
            'missing_categories': [],
            'insufficient_categories': [],
            'imbalanced_distribution': False,
            'coverage_score': 0
        }
        
        stats = self.get_basic_statistics()
        
        # æ£€æŸ¥ç¼ºå¤±ç±»åˆ«
        available_categories = set(stats['categories'].keys())
        target_categories_set = set(self.target_categories)
        
        distribution_report['missing_categories'] = list(target_categories_set - available_categories)
        
        # æ£€æŸ¥æ•°æ®ä¸è¶³çš„ç±»åˆ«
        for category in available_categories:
            total_images = sum(stats['categories'][category].values())
            if total_images < self.quality_standards['min_images_per_category']:
                distribution_report['insufficient_categories'].append({
                    'category': category,
                    'count': total_images,
                    'required': self.quality_standards['min_images_per_category']
                })
        
        # æ£€æŸ¥åˆ†å¸ƒæ˜¯å¦å‡è¡¡
        if available_categories:
            category_counts = [sum(stats['categories'][cat].values()) for cat in available_categories]
            max_count = max(category_counts)
            min_count = min(category_counts)
            
            if max_count > 3 * min_count:  # æœ€å¤§ç±»åˆ«è¶…è¿‡æœ€å°ç±»åˆ«3å€
                distribution_report['imbalanced_distribution'] = True
        
        # è®¡ç®—è¦†ç›–åº¦è¯„åˆ†
        covered_categories = len(available_categories & target_categories_set)
        distribution_report['coverage_score'] = covered_categories / len(target_categories_set) * 100
        
        return distribution_report
    
    def generate_evaluation_report(self, stats, quality_report, distribution_report):
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        report = {
            'dataset_path': str(self.dataset_path),
            'evaluation_date': pd.Timestamp.now().isoformat(),
            'summary': {
                'total_images': stats['total_images'],
                'categories_found': len(stats['categories']),
                'target_categories_covered': len(set(stats['categories'].keys()) & set(self.target_categories)),
                'overall_score': 0
            },
            'statistics': stats,
            'quality_analysis': quality_report,
            'distribution_analysis': distribution_report,
            'recommendations': []
        }
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        quality_score = quality_report['quality_score']
        coverage_score = distribution_report['coverage_score']
        report['summary']['overall_score'] = (quality_score + coverage_score) / 2
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        
        if distribution_report['missing_categories']:
            recommendations.append(f"ç¼ºå¤±ä»¥ä¸‹æ ¸å¿ƒç±»åˆ«: {', '.join(distribution_report['missing_categories'])}")
        
        if distribution_report['insufficient_categories']:
            insufficient = [item['category'] for item in distribution_report['insufficient_categories']]
            recommendations.append(f"ä»¥ä¸‹ç±»åˆ«æ•°æ®ä¸è¶³: {', '.join(insufficient)}")
        
        if quality_report['quality_score'] < 80:
            recommendations.append("å›¾åƒè´¨é‡éœ€è¦æ”¹å–„ï¼Œå»ºè®®æ£€æŸ¥åˆ†è¾¨ç‡ã€æ¸…æ™°åº¦å’Œäº®åº¦")
        
        if distribution_report['imbalanced_distribution']:
            recommendations.append("æ•°æ®åˆ†å¸ƒä¸å‡è¡¡ï¼Œå»ºè®®å¹³è¡¡å„ç±»åˆ«çš„æ ·æœ¬æ•°é‡")
        
        if stats['total_images'] < 1000:
            recommendations.append("æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œå»ºè®®å¢åŠ æ›´å¤šæ ·æœ¬ä»¥æé«˜æ¨¡å‹æ€§èƒ½")
        
        report['recommendations'] = recommendations
        
        return report
    
    def save_report(self, report):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Š"""
        # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
        json_path = self.dataset_path / "evaluation_report.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆå¯è¯»æ€§å¼ºçš„æ–‡æœ¬æŠ¥å‘Š
        text_report = self.format_text_report(report)
        text_path = self.dataset_path / "evaluation_report.txt"
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        self.logger.info(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {json_path}")
        self.logger.info(f"æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {text_path}")
    
    def format_text_report(self, report):
        """æ ¼å¼åŒ–æ–‡æœ¬æŠ¥å‘Š"""
        text = f"""
ğŸ“Š æ™ºèƒ½å†°ç®±æ•°æ®é›†è´¨é‡è¯„ä¼°æŠ¥å‘Š
======================================

ğŸ“ æ•°æ®é›†è·¯å¾„: {report['dataset_path']}
ğŸ“… è¯„ä¼°æ—¶é—´: {report['evaluation_date']}

ğŸ¯ æ€»ä½“è¯„åˆ†: {report['summary']['overall_score']:.1f}/100

ğŸ“ˆ åŸºç¡€ç»Ÿè®¡
-----------
â€¢ æ€»å›¾åƒæ•°: {report['summary']['total_images']:,}
â€¢ å‘ç°ç±»åˆ«æ•°: {report['summary']['categories_found']}
â€¢ ç›®æ ‡ç±»åˆ«è¦†ç›–: {report['summary']['target_categories_covered']}/9

ğŸ“Š æ•°æ®åˆ†å¸ƒ
-----------
"""
        
        for dataset in ['train', 'val', 'test']:
            count = report['statistics']['datasets'][dataset]
            text += f"â€¢ {dataset.upper()}é›†: {count:,} å¼ å›¾åƒ\n"
        
        text += "\nğŸ” è´¨é‡åˆ†æ\n-----------\n"
        text += f"â€¢ è´¨é‡è¯„åˆ†: {report['quality_analysis']['quality_score']:.1f}/100\n"
        text += f"â€¢ æ£€æŸ¥æ ·æœ¬æ•°: {report['quality_analysis']['total_checked']:,}\n"
        text += f"â€¢ åˆ†è¾¨ç‡é—®é¢˜: {len(report['quality_analysis']['resolution_issues'])} å¼ \n"
        text += f"â€¢ æ¨¡ç³Šé—®é¢˜: {len(report['quality_analysis']['blur_issues'])} å¼ \n"
        text += f"â€¢ äº®åº¦é—®é¢˜: {len(report['quality_analysis']['brightness_issues'])} å¼ \n"
        
        text += "\nğŸ“‹ ç±»åˆ«åˆ†æ\n-----------\n"
        text += f"â€¢ è¦†ç›–åº¦è¯„åˆ†: {report['distribution_analysis']['coverage_score']:.1f}/100\n"
        
        if report['distribution_analysis']['missing_categories']:
            text += f"â€¢ ç¼ºå¤±ç±»åˆ«: {', '.join(report['distribution_analysis']['missing_categories'])}\n"
        
        if report['distribution_analysis']['insufficient_categories']:
            text += "â€¢ æ•°æ®ä¸è¶³ç±»åˆ«:\n"
            for item in report['distribution_analysis']['insufficient_categories']:
                text += f"  - {item['category']}: {item['count']} å¼  (éœ€è¦ {item['required']} å¼ )\n"
        
        if report['recommendations']:
            text += "\nğŸ’¡ æ”¹è¿›å»ºè®®\n-----------\n"
            for i, rec in enumerate(report['recommendations'], 1):
                text += f"{i}. {rec}\n"
        
        text += "\nâœ… è¯„ä¼°å®Œæˆ\n"
        
        return text
    
    def visualize_distribution(self):
        """å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ"""
        stats = self.get_basic_statistics()
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('æ•°æ®é›†åˆ†å¸ƒåˆ†æ', fontsize=16)
        
        # 1. ç±»åˆ«åˆ†å¸ƒ
        categories = list(stats['categories'].keys())
        counts = [sum(stats['categories'][cat].values()) for cat in categories]
        
        axes[0, 0].bar(categories, counts)
        axes[0, 0].set_title('å„ç±»åˆ«å›¾åƒæ•°é‡')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. æ•°æ®é›†åˆ†å¸ƒ
        datasets = ['train', 'val', 'test']
        dataset_counts = [stats['datasets'][ds] for ds in datasets]
        
        axes[0, 1].pie(dataset_counts, labels=datasets, autopct='%1.1f%%')
        axes[0, 1].set_title('è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ†å¸ƒ')
        
        # 3. æ–‡ä»¶æ ¼å¼åˆ†å¸ƒ
        formats = list(stats['file_formats'].keys())
        format_counts = list(stats['file_formats'].values())
        
        axes[1, 0].bar(formats, format_counts)
        axes[1, 0].set_title('æ–‡ä»¶æ ¼å¼åˆ†å¸ƒ')
        
        # 4. ç±»åˆ«è¦†ç›–åº¦
        target_set = set(self.target_categories)
        available_set = set(categories)
        
        covered = len(available_set & target_set)
        missing = len(target_set - available_set)
        
        axes[1, 1].pie([covered, missing], labels=['å·²è¦†ç›–', 'ç¼ºå¤±'], autopct='%1.1f%%')
        axes[1, 1].set_title('ç›®æ ‡ç±»åˆ«è¦†ç›–åº¦')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_path = self.dataset_path / "distribution_analysis.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        self.logger.info(f"åˆ†å¸ƒå›¾è¡¨å·²ä¿å­˜: {chart_path}")
        
        plt.show()

def setup_logging(log_level=logging.INFO):
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('dataset_evaluation.log'),
            logging.StreamHandler()
        ]
    )

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ•°æ®é›†è´¨é‡è¯„ä¼°å·¥å…·")
    
    parser.add_argument("dataset_path", type=str,
                       help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--visualize", action="store_true",
                       help="ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    parser.add_argument("--log-level", type=str, default="INFO",
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(getattr(logging, args.log_level))
    logger = logging.getLogger(__name__)
    
    try:
        evaluator = DatasetEvaluator(args.dataset_path)
        
        # æ‰§è¡Œè¯„ä¼°
        report = evaluator.evaluate_dataset()
        
        # æ‰“å°æ€»ç»“
        print(f"\nğŸ¯ è¯„ä¼°å®Œæˆ!")
        print(f"æ€»ä½“è¯„åˆ†: {report['summary']['overall_score']:.1f}/100")
        print(f"å›¾åƒè´¨é‡: {report['quality_analysis']['quality_score']:.1f}/100")
        print(f"ç±»åˆ«è¦†ç›–: {report['distribution_analysis']['coverage_score']:.1f}/100")
        
        if report['recommendations']:
            print("\nğŸ’¡ ä¸»è¦å»ºè®®:")
            for rec in report['recommendations'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                print(f"  â€¢ {rec}")
        
        # å¯è§†åŒ–
        if args.visualize:
            evaluator.visualize_distribution()
        
        logger.info("æ•°æ®é›†è¯„ä¼°å®Œæˆ")
        
    except Exception as e:
        logger.error(f"è¯„ä¼°å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()