#!/usr/bin/env python3
"""
è®­ç»ƒç»“æœåˆ†æè„šæœ¬
åˆ†æå’Œå¯¹æ¯”ä¸åŒè®­ç»ƒæ–¹æ³•çš„ç»“æœ
"""

import os
import sys
import json
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import seaborn as sns
from datetime import datetime
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def analyze_models():
    """åˆ†æå’Œå¯¹æ¯”æ¨¡å‹è®­ç»ƒç»“æœ"""
    
    # æ¨¡å‹ç›®å½•
    original_dir = Path("ai_model/trained_models")
    optimized_dir = Path("ai_model/trained_models_optimized")
    
    print("=" * 60)
    print("ğŸ” æ™ºèƒ½å†°ç®±AIæ¨¡å‹è®­ç»ƒç»“æœå¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    models_info = {}
    
    # åŸå§‹è®­ç»ƒç»“æœ
    if original_dir.exists():
        original_metadata = original_dir / "class_indices.json"
        if original_metadata.exists():
            with open(original_metadata, 'r', encoding='utf-8') as f:
                original_classes = json.load(f)
            
            original_h5 = list(original_dir.glob("*.h5"))
            original_tflite = list(original_dir.glob("*.tflite"))
            
            models_info['original'] = {
                'dir': original_dir,
                'classes': original_classes,
                'h5_files': original_h5,
                'tflite_files': original_tflite,
                'name': 'åŸå§‹è®­ç»ƒ'
            }
    
    # ä¼˜åŒ–è®­ç»ƒç»“æœ
    if optimized_dir.exists():
        optimized_metadata = optimized_dir / "model_metadata.json"
        if optimized_metadata.exists():
            with open(optimized_metadata, 'r', encoding='utf-8') as f:
                optimized_data = json.load(f)
            
            optimized_h5 = list(optimized_dir.glob("*.h5"))
            optimized_tflite = list(optimized_dir.glob("*.tflite"))
            
            models_info['optimized'] = {
                'dir': optimized_dir,
                'metadata': optimized_data,
                'classes': optimized_data.get('class_indices', {}),
                'h5_files': optimized_h5,
                'tflite_files': optimized_tflite,
                'name': 'ä¼˜åŒ–è®­ç»ƒ'
            }
    
    if not models_info:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœ")
        return
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(models_info)
    
    # ç”Ÿæˆæ–‡ä»¶å¤§å°å¯¹æ¯”
    generate_size_comparison(models_info)
    
    # ç”Ÿæˆå»ºè®®æŠ¥å‘Š
    generate_recommendations(models_info)

def generate_comparison_report(models_info):
    """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š"""
    
    print("\nğŸ“Š æ¨¡å‹å¯¹æ¯”åˆ†æ")
    print("-" * 40)
    
    comparison_data = []
    
    for key, info in models_info.items():
        model_name = info['name']
        classes = info['classes']
        h5_files = info['h5_files']
        tflite_files = info['tflite_files']
        
        # åŸºæœ¬ä¿¡æ¯
        num_classes = len(classes)
        h5_size = sum([f.stat().st_size for f in h5_files]) / (1024*1024) if h5_files else 0
        tflite_size = sum([f.stat().st_size for f in tflite_files]) / (1024*1024) if tflite_files else 0
        
        row_data = {
            'æ¨¡å‹ç‰ˆæœ¬': model_name,
            'ç±»åˆ«æ•°é‡': num_classes,
            'H5å¤§å°(MB)': f"{h5_size:.1f}",
            'TFLiteå¤§å°(MB)': f"{tflite_size:.1f}",
            'ç±»åˆ«': list(classes.keys())
        }
        
        # æ·»åŠ ä¼˜åŒ–ç‰ˆæœ¬çš„é¢å¤–ä¿¡æ¯
        if 'metadata' in info:
            metadata = info['metadata']
            row_data.update({
                'å‚æ•°æ•°é‡': f"{metadata.get('total_params', 0):,}",
                'è®­ç»ƒæ—¶é—´(ç§’)': f"{metadata.get('training_time', 0):.1f}",
                'è®­ç»ƒæ ·æœ¬': metadata.get('dataset_info', {}).get('train_samples', 0),
                'éªŒè¯æ ·æœ¬': metadata.get('dataset_info', {}).get('val_samples', 0),
                'æµ‹è¯•æ ·æœ¬': metadata.get('dataset_info', {}).get('test_samples', 0)
            })
        
        comparison_data.append(row_data)
        
        print(f"\nğŸ¯ {model_name}:")
        print(f"  â€¢ ç±»åˆ«æ•°é‡: {num_classes}")
        print(f"  â€¢ è¯†åˆ«ç±»åˆ«: {', '.join(classes.keys())}")
        print(f"  â€¢ H5æ¨¡å‹å¤§å°: {h5_size:.1f} MB")
        print(f"  â€¢ TFLiteæ¨¡å‹å¤§å°: {tflite_size:.1f} MB")
        
        if 'metadata' in info:
            metadata = info['metadata']
            print(f"  â€¢ æ¨¡å‹å‚æ•°: {metadata.get('total_params', 0):,}")
            print(f"  â€¢ è®­ç»ƒæ—¶é—´: {metadata.get('training_time', 0):.1f} ç§’")
            dataset_info = metadata.get('dataset_info', {})
            print(f"  â€¢ æ•°æ®åˆ†å¸ƒ: è®­ç»ƒ{dataset_info.get('train_samples', 0)} + éªŒè¯{dataset_info.get('val_samples', 0)} + æµ‹è¯•{dataset_info.get('test_samples', 0)}")
    
    # ä¿å­˜å¯¹æ¯”è¡¨æ ¼
    if comparison_data:
        df = pd.DataFrame(comparison_data)
        output_file = Path("ai_model/model_comparison.csv")
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜: {output_file}")

def generate_size_comparison(models_info):
    """ç”Ÿæˆæ–‡ä»¶å¤§å°å¯¹æ¯”å›¾"""
    
    if len(models_info) < 2:
        return
    
    plt.figure(figsize=(12, 6))
    
    # å‡†å¤‡æ•°æ®
    model_names = []
    h5_sizes = []
    tflite_sizes = []
    
    for key, info in models_info.items():
        model_names.append(info['name'])
        
        h5_files = info['h5_files']
        tflite_files = info['tflite_files']
        
        h5_size = sum([f.stat().st_size for f in h5_files]) / (1024*1024) if h5_files else 0
        tflite_size = sum([f.stat().st_size for f in tflite_files]) / (1024*1024) if tflite_files else 0
        
        h5_sizes.append(h5_size)
        tflite_sizes.append(tflite_size)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    x = np.arange(len(model_names))
    width = 0.35
    
    plt.subplot(1, 2, 1)
    plt.bar(x - width/2, h5_sizes, width, label='H5æ¨¡å‹', alpha=0.8, color='skyblue')
    plt.bar(x + width/2, tflite_sizes, width, label='TFLiteæ¨¡å‹', alpha=0.8, color='lightcoral')
    
    plt.xlabel('æ¨¡å‹ç‰ˆæœ¬')
    plt.ylabel('æ–‡ä»¶å¤§å° (MB)')
    plt.title('æ¨¡å‹æ–‡ä»¶å¤§å°å¯¹æ¯”')
    plt.xticks(x, model_names)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (h5, tflite) in enumerate(zip(h5_sizes, tflite_sizes)):
        plt.text(i - width/2, h5 + 0.1, f'{h5:.1f}MB', ha='center', va='bottom')
        plt.text(i + width/2, tflite + 0.1, f'{tflite:.1f}MB', ha='center', va='bottom')
    
    # å‹ç¼©æ¯”å¯¹æ¯”
    plt.subplot(1, 2, 2)
    compression_ratios = [h5/tflite if tflite > 0 else 0 for h5, tflite in zip(h5_sizes, tflite_sizes)]
    
    bars = plt.bar(model_names, compression_ratios, alpha=0.8, color='lightgreen')
    plt.xlabel('æ¨¡å‹ç‰ˆæœ¬')
    plt.ylabel('å‹ç¼©æ¯” (H5/TFLite)')
    plt.title('TFLiteå‹ç¼©æ•ˆæœ')
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, ratio in zip(bars, compression_ratios):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{ratio:.1f}x', ha='center', va='bottom')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_file = Path("ai_model/model_size_comparison.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š å¤§å°å¯¹æ¯”å›¾å·²ä¿å­˜: {output_file}")

def generate_recommendations(models_info):
    """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®å’Œæ€»ç»“")
    print("-" * 40)
    
    # æ ¹æ®å¯¹æ¯”ç»“æœç”Ÿæˆå»ºè®®
    if 'optimized' in models_info and 'original' in models_info:
        optimized = models_info['optimized']
        original = models_info['original']
        
        print("âœ… æˆåŠŸå®Œæˆæ¨¡å‹è®­ç»ƒä¼˜åŒ–ï¼")
        
        # æ£€æŸ¥æ”¹è¿›æƒ…å†µ
        opt_metadata = optimized.get('metadata', {})
        training_time = opt_metadata.get('training_time', 0)
        
        print(f"\nğŸš€ ä¼˜åŒ–è®­ç»ƒçš„æ”¹è¿›:")
        print(f"  â€¢ ä½¿ç”¨äº†å¢å¼ºçš„æ•°æ®é¢„å¤„ç†å’Œæ•°æ®å¢å¼ºæŠ€æœ¯")
        print(f"  â€¢ è®­ç»ƒæ—¶é—´: {training_time:.1f} ç§’ (çº¦{training_time/60:.1f} åˆ†é’Ÿ)")
        print(f"  â€¢ æ¨¡å‹å‚æ•°: {opt_metadata.get('total_params', 0):,}")
        print(f"  â€¢ æ­£ç¡®è¯†åˆ«6ä¸ªé£Ÿç‰©ç±»åˆ«: {', '.join(optimized['classes'].keys())}")
        
        # æ•°æ®é›†å»ºè®®
        dataset_info = opt_metadata.get('dataset_info', {})
        total_samples = sum(dataset_info.values())
        print(f"\nğŸ“Š æ•°æ®é›†çŠ¶å†µ:")
        print(f"  â€¢ å½“å‰æ ·æœ¬æ•°: {total_samples}")
        print(f"  â€¢ å»ºè®®å¢åŠ æ ·æœ¬åˆ°: 1000+ å¼ /ç±»åˆ« (å½“å‰çº¦{total_samples//6}å¼ /ç±»åˆ«)")
        
        # ç¼ºå¤±ç±»åˆ«æé†’
        expected_categories = {'milk', 'beef', 'vegetables', 'yogurt', 'cheese', 'chicken', 'dairy', 'eggs', 'fish', 'fruits'}
        current_categories = set(optimized['classes'].keys())
        missing_categories = expected_categories - current_categories
        
        if missing_categories:
            print(f"  â€¢ ç¼ºå¤±ç±»åˆ«: {', '.join(missing_categories)}")
            print(f"  â€¢ å»ºè®®è¡¥å……è¿™äº›ç±»åˆ«çš„æ•°æ®ä»¥æé«˜ç³»ç»Ÿå®Œæ•´æ€§")
    
    elif 'optimized' in models_info:
        print("âœ… å®Œæˆä¼˜åŒ–è®­ç»ƒï¼")
        optimized = models_info['optimized']
        opt_metadata = optimized.get('metadata', {})
        
        print(f"  â€¢ æˆåŠŸè®­ç»ƒ{len(optimized['classes'])}ç±»é£Ÿç‰©åˆ†ç±»æ¨¡å‹")
        print(f"  â€¢ è®­ç»ƒæ—¶é—´: {opt_metadata.get('training_time', 0):.1f} ç§’")
    
    else:
        print("âš ï¸ ä»…å‘ç°åŸå§‹è®­ç»ƒç»“æœ")
        print("  â€¢ å»ºè®®è¿è¡Œä¼˜åŒ–è®­ç»ƒè„šæœ¬ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
    
    # éƒ¨ç½²å»ºè®®
    print(f"\nğŸš€ éƒ¨ç½²å»ºè®®:")
    print(f"  â€¢ H5æ¨¡å‹: é€‚ç”¨äºæœåŠ¡å™¨ç«¯éƒ¨ç½²ï¼Œç²¾åº¦æœ€é«˜")
    print(f"  â€¢ TFLiteæ¨¡å‹: é€‚ç”¨äºç§»åŠ¨è®¾å¤‡å’Œè¾¹ç¼˜è®¡ç®—ï¼Œä½“ç§¯å°")
    print(f"  â€¢ æ¨èåœ¨æ™ºèƒ½å†°ç®±ç¡¬ä»¶ä¸Šä½¿ç”¨TFLiteæ¨¡å‹")
    
    # åç»­ä¼˜åŒ–å»ºè®®
    print(f"\nğŸ”§ åç»­ä¼˜åŒ–æ–¹å‘:")
    print(f"  1. æ”¶é›†æ›´å¤šçœŸå®å†°ç®±é£Ÿç‰©å›¾åƒæ•°æ®")
    print(f"  2. æ·»åŠ ç¼ºå¤±çš„é£Ÿç‰©ç±»åˆ« (ç‰›å¥¶ã€ç‰›è‚‰ã€è”¬èœã€é…¸å¥¶)")
    print(f"  3. å®æ–½æ¨¡å‹é‡åŒ–ä»¥è¿›ä¸€æ­¥å‡å°TFLiteæ¨¡å‹ä½“ç§¯")
    print(f"  4. è€ƒè™‘ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹æ¶æ„ (å¦‚EfficientNet)")
    print(f"  5. æ·»åŠ æ¨¡å‹æ€§èƒ½ç›‘æ§å’Œåœ¨çº¿å­¦ä¹ åŠŸèƒ½")

def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
    os.chdir(project_root)
    
    try:
        analyze_models()
        print(f"\nğŸ‰ è®­ç»ƒç»“æœåˆ†æå®Œæˆï¼")
        print(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()